# Chaotic Time Series ESN (MSLP)

**Architecture:** InputConv(1â†’256) â†’ FC(256â†’1)
**Status:** ğŸ“‹ Analysis complete; extends ecoPrimals ESN readout
**Task:** Predict next step in chaotic MSLP (Mean Sea Level Pressure) time series
**Source:** NeuroBench chaotic prediction benchmark; Lorenz-like atmospheric data

---

## Connection to ecoPrimals ESN

This is architecturally identical to `models/physics/esn_readout.md`:

| | MSLP ESN | hotSpring ESN |
|--|---------|--------------|
| Architecture | InputConv(1â†’256) â†’ FC(256â†’1) | InputConv(50â†’128) â†’ FC(128â†’1) |
| Input | 1 value (current step) | 50 values (plaquette history) |
| Output | 1 prediction (next step) | 1 flag (thermalization) |
| Reservoir | 256 NPs | 128 NPs |
| Task | Atmosphere prediction | QCD monitoring |
| Training data | MSLP atmospheric pressure | SU(3) lattice plaquette |

The difference is only the training domain and reservoir size.
The hardware execution path is identical â€” same Akida program structure.

---

## Architecture

```
CPU reservoir (fixed random W_res, 256Ã—256):
  x(t+1) = tanh(W_res Ã— x(t) + W_in Ã— u(t))
  u(t) = current MSLP value (scalar)

Akida readout:
Input: float[256]  (reservoir activations at time t)
  â”‚
  â–¼
InputConv(1â†’256, kernel=1)    â† maps 256 activations to 256 NPs
  â”‚
  â–¼
FC(256â†’1)                     â† linear readout W_out (trained by least squares)
  â”‚
  â–¼
Output: float[1]  (predicted MSLP at t+1)
```

---

## NeuroBench Results

| Metric | Value |
|--------|-------|
| sMAPE | 3.8% |
| Throughput | ~18,000 Hz |
| Energy | ~1.4 ÂµJ |

sMAPE (symmetric mean absolute percentage error) below 4% on chaotic prediction
is competitive with full LSTM models while running at 18,000Ã— less energy.

---

## The Reservoir Computing Advantage for Akida

Why ESN maps so naturally to Akida:

1. **Reservoir is random and fixed** â€” trained once, never changes.
   The chip only runs the readout, not the reservoir dynamics.

2. **Readout is linear** â€” FC layer with least-squares weights.
   Int4 quantization loses very little precision for linear regression.

3. **Input history is compressed** â€” 256 reservoir activations summarize
   the entire temporal history of the input. Akida sees 256 floats, not
   a time series.

4. **Speed matters** â€” at 18,000 Hz, the readout keeps up with any
   real-time input stream (sensors, simulation, audio).

This makes reservoir computing the **ideal neuromorphic workload**:
the compute-intensive (reservoir) runs on CPU/GPU, the fast readout on NPU.

---

## ecoPrimals Extensions

| Extension | Description |
|-----------|-------------|
| Multi-step prediction | FC(256â†’10) for 10-step ahead forecast |
| Multi-variable | FC(256â†’3) for {MSLP, temperature, humidity} |
| Online adaptation | set_variable() to swap W_out at 86 Âµs (Discovery 6) |
| Ensemble readout | 3 classifiers hot-swapped, majority vote |
| Physics hybrid | Same reservoir, different readouts per domain |

The ensemble readout (3 classifiers) is demonstrated in hotSpring Exp 022
and wetSpring Exp 193â€“195 (NPU sentinel, online evolution at 136 gen/sec).
